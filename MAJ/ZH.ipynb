{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as k\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import os, argparse, random, pickle, cv2, fnmatch\n",
    "from os.path import join\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels\n",
    "## Create a list of the paths of the files that contain the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48398, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels = []\n",
    "def find_files(directory, pattern):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for basename in files:\n",
    "            if fnmatch.fnmatch(basename, pattern):\n",
    "                filename = os.path.join(root, basename)\n",
    "                yield filename\n",
    "\n",
    "\n",
    "for filename in find_files('/data/home/maj/notebooks/w210-final-project/MAJ/Frame_Labels/PSPI/', '*.txt'):\n",
    "    Labels.append(filename)\n",
    "\n",
    "Labels_df = pd.DataFrame(data=Labels)\n",
    "\n",
    "Labels_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images\n",
    "## Create a list of the paths of the files that contain the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48398, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_path = []\n",
    "def find_files(directory, pattern):\n",
    "   for root, dirs, files in os.walk(directory):\n",
    "       for basename in files:\n",
    "           if fnmatch.fnmatch(basename, pattern):\n",
    "               filename = os.path.join(root, basename)\n",
    "               yield filename\n",
    "\n",
    "\n",
    "for filename in find_files('/data/home/maj/notebooks/w210-final-project/MAJ', '*.png'):\n",
    "   images_path.append(filename)\n",
    "\n",
    "images_path_df = pd.DataFrame(data=images_path)\n",
    "\n",
    "images_path_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a list of images\n",
    "## This is the part I don't understand.  We need to simplify this, or package it in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "sequences = []\n",
    "image_sequences = []\n",
    "\n",
    "pspi_scores = []\n",
    "opr_scores = []\n",
    "\n",
    "aff_scores = []\n",
    "sen_scores = []\n",
    "vas_scores = []\n",
    "\n",
    "for subject_id in os.listdir('Images'):\n",
    "    if subject_id != '.DS_Store':\n",
    "        for sequence_id in os.listdir(join('Images', subject_id)):\n",
    "            if sequence_id != '.DS_Store':\n",
    "                sequences.append(sequence_id)\n",
    "                for image in os.listdir(join('Images', subject_id, sequence_id)):\n",
    "                    if image != '.DS_Store':\n",
    "                        images.append(image.split('.')[0])\n",
    "                        image_sequences.append(sequence_id)\n",
    "                for pspi_file in os.listdir(join('Frame_Labels', 'PSPI', subject_id, sequence_id)):\n",
    "                    with open(join('Frame_Labels', 'PSPI', subject_id, sequence_id, pspi_file), 'r') as f_in:\n",
    "                        pspi_scores.append(float(f_in.read().strip()))\n",
    "        for aff_file in os.listdir(join('Sequence_Labels', 'AFF', subject_id)):\n",
    "            with open(join('Sequence_Labels', 'AFF', subject_id, aff_file), 'r') as f_in:\n",
    "                aff_scores.append(float(f_in.read().strip()))\n",
    "        for opr_file in os.listdir(join('Sequence_Labels', 'OPR', subject_id)):\n",
    "            with open(join('Sequence_Labels', 'OPR', subject_id, opr_file), 'r') as f_in:\n",
    "                opr_scores.append(float(f_in.read().strip()))\n",
    "        for sen_file in os.listdir(join('Sequence_Labels', 'SEN', subject_id)):\n",
    "            with open(join('Sequence_Labels', 'SEN', subject_id, sen_file), 'r') as f_in:\n",
    "                sen_scores.append(float(f_in.read().strip()))\n",
    "        for vas_file in os.listdir(join('Sequence_Labels', 'VAS', subject_id)):\n",
    "            with open(join('Sequence_Labels', 'VAS', subject_id, vas_file), 'r') as f_in:\n",
    "                vas_scores.append(float(f_in.read().strip()))\n",
    "\n",
    "image_data = {'image': images,\n",
    "              'image_sequence': image_sequences,\n",
    "              'pspi_score': pspi_scores}\n",
    "\n",
    "sequence_data = {'sequence': sequences, \n",
    "                 'aff_score': aff_scores, \n",
    "                 'opr_score': opr_scores, \n",
    "                 'sen_score': sen_scores,\n",
    "                 'vas_score': vas_scores}\n",
    "\n",
    "image_df = pd.DataFrame(data=image_data)\n",
    "sequence_df = pd.DataFrame(data=sequence_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of image identifiers:\n",
      "['fn059t2afunaff048', 'fn059t2afunaff405', 'fn059t2afunaff119', 'fn059t2afunaff163', 'fn059t2afunaff003', 'fn059t2afunaff005', 'fn059t2afunaff022', 'fn059t2afunaff176', 'fn059t2afunaff287', 'fn059t2afunaff257']\n",
      "\n",
      "Examples of sequence identifiers:\n",
      "['fn059t2afunaff', 'fn059t2aiaff', 'jh043t2afunaff', 'jh043t2afaff', 'jh043t2aeunaff', 'jh043t2aiunaff', 'jh043t1afaff', 'jh043t2aeaff', 'jh043t2aaunaff', 'jh043t1aeaff']\n",
      "\n",
      "Examples of PSPI scores:\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Examples of AFF scores:\n",
      "[7.0, 1.0, 4.0, 1.0, 1.0, 4.0, 1.0, 1.0, 13.0, 5.0]\n",
      "\n",
      "Examples of OPR scores:\n",
      "[4.0, 3.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 1.0]\n",
      "\n",
      "Examples of SEN scores:\n",
      "[8.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 12.0, 5.0]\n",
      "\n",
      "Examples of VAS scores:\n",
      "[6.0, 1.0, 2.0, 0.0, 0.0, 4.0, 0.0, 1.0, 6.0, 3.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('Examples of image identifiers:\\n{}\\n'.format(images[:10]))\n",
    "print ('Examples of sequence identifiers:\\n{}\\n'.format(sequences[:10]))\n",
    "print ('Examples of PSPI scores:\\n{}\\n'.format(pspi_scores[:10]))\n",
    "print ('Examples of AFF scores:\\n{}\\n'.format(aff_scores[:10]))\n",
    "print ('Examples of OPR scores:\\n{}\\n'.format(opr_scores[:10]))\n",
    "print ('Examples of SEN scores:\\n{}\\n'.format(sen_scores[:10]))\n",
    "print ('Examples of VAS scores:\\n{}\\n'.format(vas_scores[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pain_data = image_df[['image','pspi_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          image_path              image\n",
      "0  /data/home/maj/notebooks/w210-final-project/MA...  fn059t2afunaff048\n",
      "\n",
      "Final Dataset ready for CNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>image</th>\n",
       "      <th>pspi_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/home/maj/notebooks/w210-final-project/MA...</td>\n",
       "      <td>fn059t2afunaff048</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path              image  \\\n",
       "0  /data/home/maj/notebooks/w210-final-project/MA...  fn059t2afunaff048   \n",
       "\n",
       "   pspi_score  \n",
       "0         0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting the .png file name from the first dataset and joining with the image & PSPI score dataset\n",
    "images_path_df\n",
    "\n",
    "#renaming dataframe column to image path\n",
    "images_path_df.columns = ['image_path']\n",
    "\n",
    "# new temp data frame with split value columns \n",
    "temp = images_path_df[\"image_path\"].str.split(\"/\", n = 10, expand = True) \n",
    "temp.columns = ['zero','one','two','three','four','five','six','seven', 'eight','nine', 'ten']\n",
    "\n",
    "\n",
    "# Create new temp dataframe that has image name without .png to later do a merge\n",
    "temp2 = temp[\"ten\"].str.split(\".\", n = 1, expand = True) \n",
    "temp2.columns = ['image','ext']\n",
    "temp2.drop(columns =[\"ext\"], inplace = True) \n",
    "\n",
    "# print(temp2[:1])\n",
    "# print(images_path_df[:1])\n",
    "\n",
    "df_columns = pd.concat([images_path_df, temp2], axis =1)\n",
    "print(df_columns[:1])\n",
    "\n",
    "# #checking the size\n",
    "# print('manip:', df_columns.shape)\n",
    "# print('original:', pain_data.shape)\n",
    "\n",
    "# #checking the header and first row for each data frame\n",
    "# print(df_columns[:1])\n",
    "# print(pain_data[:1])\n",
    "\n",
    "#doing a merge on the .png value to ensure that the path will match the PSPI value\n",
    "merged_inner = pd.merge(left=pain_data,right=df_columns, left_on='image', right_on='image')\n",
    "# print('merged table: ', merged_inner.shape)\n",
    "# print('New table header: ',merged_inner[:1])\n",
    "\n",
    "#reordering columns\n",
    "merged_inner= merged_inner [['image_path', 'image', 'pspi_score']]\n",
    "merged_inner[:1]\n",
    "\n",
    "#Final Dataset for pain dataset to by used in CNN\n",
    "pain_data = merged_inner\n",
    "print('\\nFinal Dataset ready for CNN')\n",
    "\n",
    "pain_data[:1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & Save to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO] Pictures loaded\n",
      "[INFO] Array of data: (48398, 240, 320, 3), array of labels: (48398,)\n",
      "[INFO] Saving ...\n",
      "[INFO] Datasets Saved\n"
     ]
    }
   ],
   "source": [
    "# Shuffle Dataset\n",
    "random.seed(42)\n",
    "pain_data = shuffle(pain_data)\n",
    "\n",
    "# initialize the data and labels\n",
    "\n",
    "\n",
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "# data_pic = []\n",
    "imagelist = [] #markedbymark\n",
    "pic_path = []\n",
    "# labels = pain_data['pspi_score']\n",
    "labellist = pain_data['pspi_score'].tolist() #markedbymark\n",
    "\n",
    "# loop over the input images\n",
    "imagePath = list(pain_data['image_path'])\n",
    "\n",
    "for imagePath in imagePath:\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (320, 240)) # resize\n",
    "    imagelist.append(image)\n",
    "    pic_path.append(imagePath)\n",
    "    \n",
    "print(\"[INFO] Pictures loaded\")\n",
    "\n",
    "finalArray = np.array(imagelist)\n",
    "finalLabels = np.array(labellist)\n",
    "print('[INFO] Array of data: {}, array of labels: {}'.format(finalArray.shape, finalLabels.shape))\n",
    "print('[INFO] Saving ...')\n",
    "np.save('ArrayOfImages', finalArray)\n",
    "np.save('Labels', finalLabels)\n",
    "print('[INFO] Datasets Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data\t: (33878, 240, 320, 3)\n",
      "Train Labels\t: (33878,)\n",
      "Test Data\t: (14520, 240, 320, 3)\n",
      "Test Labels\t: (14520,)\n"
     ]
    }
   ],
   "source": [
    "test_ratio = 0.3\n",
    "split_location = int(finalArray.shape[0]*(1-test_ratio))\n",
    "train_data = finalArray[:split_location]\n",
    "test_data = finalArray[split_location:]\n",
    "\n",
    "train_labels = finalLabels[:split_location]\n",
    "test_labels = finalLabels[split_location:]\n",
    "\n",
    "print('Train Data\\t: {}\\nTrain Labels\\t: {}\\nTest Data\\t: {}\\nTest Labels\\t: {}'\n",
    "      .format(train_data.shape, train_labels.shape, test_data.shape, test_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33878/33878 [==============================] - 33s 988us/sample - loss: 16.0919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb6964d9240>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(16, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "# markedbymark\n",
    "model.fit(train_data, train_labels, epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14520/14520 [==============================] - 13s 914us/sample - loss: 2.8384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.8384410419411568"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
